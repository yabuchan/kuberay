{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 KubeRay \u00b6 KubeRay is an open source toolkit to run Ray applications on Kubernetes. KubeRay provides several tools to improve running and managing Ray's experience on Kubernetes. Ray Operator Backend services to create/delete cluster resources Kubectl plugin/CLI to operate CRD objects Data Scientist centric workspace for fast prototyping (incubating) Native Job and Serving integration with Clusters (incubating) Kubernetes event dumper for ray clusters/pod/services (future work) Operator Integration with Kubernetes node problem detector (future work) Security \u00b6 If you discover a potential security issue in this project, or think you may have discovered a security issue, we ask that you notify KubeRay Security via our Slack Channel . Please do not create a public GitHub issue. License \u00b6 This project is licensed under the Apache-2.0 License .","title":"Welcome"},{"location":"#welcome","text":"","title":"Welcome"},{"location":"#kuberay","text":"KubeRay is an open source toolkit to run Ray applications on Kubernetes. KubeRay provides several tools to improve running and managing Ray's experience on Kubernetes. Ray Operator Backend services to create/delete cluster resources Kubectl plugin/CLI to operate CRD objects Data Scientist centric workspace for fast prototyping (incubating) Native Job and Serving integration with Clusters (incubating) Kubernetes event dumper for ray clusters/pod/services (future work) Operator Integration with Kubernetes node problem detector (future work)","title":"KubeRay"},{"location":"#security","text":"If you discover a potential security issue in this project, or think you may have discovered a security issue, we ask that you notify KubeRay Security via our Slack Channel . Please do not create a public GitHub issue.","title":"Security"},{"location":"#license","text":"This project is licensed under the Apache-2.0 License .","title":"License"},{"location":"troubleshooting/","text":"Troubleshooting handbook \u00b6 Introduction \u00b6 This page will give you some guild on troubleshooting for some situations when you deploy and use the kuberay. Ray Version Compatibility \u00b6 Problem \u00b6 For every running ray cluster, when we try to connect with the client, we must be careful about the python and ray version we used. There are several issues report failures related to version imcompatibility: #148 , #21549 . Therefore there is a reminder for troubleshooting when come up with that situation. Error cases \u00b6 In the ray client initialization, there are several checks will be executed in ray-project/ray/util/client/__init__.py:L115-L137 . Common cases would be like: ... RuntimeError: Python minor versions differ between client and server: client is 3 .8.10, server is 3 .7.7 or: ... RuntimeError: Client Ray installation incompatible with server: client is 2021 -05-20, server is 2021 -12-07 Some cases may not be so clear: ConnectionAbortedError: Initialization failure from server: Traceback ( most recent call last ) : ... 'AttributeError: ''JobConfig'' object has no attribute ''_parsed_runtime_env' ' Traceback (most recent call last): ... RuntimeError: Version mismatch: The cluster was started with: Ray: 1.9.0 Python: 3.7.7 This process on node NODE_ADDRESS was started with: Ray: 1.10.0 Python: 3.7.7 Solution \u00b6 In above cases, you will need to check if the client ray version is compatible with the images version in the ray cluster's configuration. For example, when you deployed kuberay/ray-operator/config/samples/ray-cluster.mini.yaml , you need to be aware that spec.rayVersion and images version is the same with your expect ray release and same with your ray client version. NOTE: In ray code, the version check will only go through major and minor version, so the python and ray image's minor version match is enough. Also the ray upstream community provide different python version support from 3.6 to 3.9, you can choose the image to match your python version.","title":"Guidance"},{"location":"troubleshooting/#troubleshooting-handbook","text":"","title":"Troubleshooting handbook"},{"location":"troubleshooting/#introduction","text":"This page will give you some guild on troubleshooting for some situations when you deploy and use the kuberay.","title":"Introduction"},{"location":"troubleshooting/#ray-version-compatibility","text":"","title":"Ray Version Compatibility"},{"location":"troubleshooting/#problem","text":"For every running ray cluster, when we try to connect with the client, we must be careful about the python and ray version we used. There are several issues report failures related to version imcompatibility: #148 , #21549 . Therefore there is a reminder for troubleshooting when come up with that situation.","title":"Problem"},{"location":"troubleshooting/#error-cases","text":"In the ray client initialization, there are several checks will be executed in ray-project/ray/util/client/__init__.py:L115-L137 . Common cases would be like: ... RuntimeError: Python minor versions differ between client and server: client is 3 .8.10, server is 3 .7.7 or: ... RuntimeError: Client Ray installation incompatible with server: client is 2021 -05-20, server is 2021 -12-07 Some cases may not be so clear: ConnectionAbortedError: Initialization failure from server: Traceback ( most recent call last ) : ... 'AttributeError: ''JobConfig'' object has no attribute ''_parsed_runtime_env' ' Traceback (most recent call last): ... RuntimeError: Version mismatch: The cluster was started with: Ray: 1.9.0 Python: 3.7.7 This process on node NODE_ADDRESS was started with: Ray: 1.10.0 Python: 3.7.7","title":"Error cases"},{"location":"troubleshooting/#solution","text":"In above cases, you will need to check if the client ray version is compatible with the images version in the ray cluster's configuration. For example, when you deployed kuberay/ray-operator/config/samples/ray-cluster.mini.yaml , you need to be aware that spec.rayVersion and images version is the same with your expect ray release and same with your ray client version. NOTE: In ray code, the version check will only go through major and minor version, so the python and ray image's minor version match is enough. Also the ray upstream community provide different python version support from 3.6 to 3.9, you can choose the image to match your python version.","title":"Solution"},{"location":"best-practice/worker-head-reconnection/","text":"Explanation and Best Practice for workers-head Reconnection \u00b6 Problem \u00b6 For a RayCluster with a head and several workers, if a worker is crashed, it will be relaunched immediately and re-join the same cluster quickly; however, when the head is crashed, it will run into the issue #104 that all worker nodes are lost from the head for a long period of time. Explanation \u00b6 When the head pod was deleted, it will be recreated with a new IP by KubeRay controller\uff0cand the GCS server address is changed accordingly. The Raylets of all workers will try to get GCS address from Redis in \u2018ReconnectGcsServer\u2019, but the redis_clients always use the previous head IP, so they will always fail to get new GCS address. The Raylets will not exit until max retries are reached. There are two configurations determining this long delay: /// The interval at which the gcs rpc client will check if gcs rpc server is ready. RAY_CONFIG(int64_t, ping_gcs_rpc_server_interval_milliseconds, 1000) /// Maximum number of times to retry ping gcs rpc server when gcs server restarts. RAY_CONFIG(int32_t, ping_gcs_rpc_server_max_retries, 600) https://github.com/ray-project/ray/blob/98be9fb5e08befbd6cac3ffbcaa477c5117b0eef/src/ray/gcs/gcs_client/gcs_client.cc#L294-L295 It retries 600 times and each interval is 1s, resulting in total 600s timeout, i.e. 10 min. So immediately after 10-min wait for retries, each client exits and gets restarted while connecting to the new head IP. This issue exists in all stable ray versions (including 1.9.1). This has been reduced to 60s in recent commit in master. Best Practice \u00b6 GCS HA feature #20498 is planned in Ray Core Roadmap. When this feature is released, expect a stable head and GCS such that worker-head connection lost issue will not appear anymore. Before that, to solve the workers-head connection lost, there are two options: Make head more stable: when creating the cluster, allocate sufficient amount of resources on head pod such that it tends to be stable and not easy to crash. You can also set {\"num-cpus\": \"0\"} in \"rayStartParams\" of \"headGroupSpec\" such that Ray scheduler will skip the head node when scheduling workloads. This also helps to maintain the stability of the head. Make reconnection shorter: for version <= 1.9.1, you can set this head param --system-config='{\"ping_gcs_rpc_server_max_retries\": 20}' to reduce the delay from 600s down to 20s before workers reconnect to the new head. Note: we should update this doc when GCS HA feature gets updated.","title":"Worker reconnection"},{"location":"best-practice/worker-head-reconnection/#explanation-and-best-practice-for-workers-head-reconnection","text":"","title":"Explanation and Best Practice for workers-head Reconnection"},{"location":"best-practice/worker-head-reconnection/#problem","text":"For a RayCluster with a head and several workers, if a worker is crashed, it will be relaunched immediately and re-join the same cluster quickly; however, when the head is crashed, it will run into the issue #104 that all worker nodes are lost from the head for a long period of time.","title":"Problem"},{"location":"best-practice/worker-head-reconnection/#explanation","text":"When the head pod was deleted, it will be recreated with a new IP by KubeRay controller\uff0cand the GCS server address is changed accordingly. The Raylets of all workers will try to get GCS address from Redis in \u2018ReconnectGcsServer\u2019, but the redis_clients always use the previous head IP, so they will always fail to get new GCS address. The Raylets will not exit until max retries are reached. There are two configurations determining this long delay: /// The interval at which the gcs rpc client will check if gcs rpc server is ready. RAY_CONFIG(int64_t, ping_gcs_rpc_server_interval_milliseconds, 1000) /// Maximum number of times to retry ping gcs rpc server when gcs server restarts. RAY_CONFIG(int32_t, ping_gcs_rpc_server_max_retries, 600) https://github.com/ray-project/ray/blob/98be9fb5e08befbd6cac3ffbcaa477c5117b0eef/src/ray/gcs/gcs_client/gcs_client.cc#L294-L295 It retries 600 times and each interval is 1s, resulting in total 600s timeout, i.e. 10 min. So immediately after 10-min wait for retries, each client exits and gets restarted while connecting to the new head IP. This issue exists in all stable ray versions (including 1.9.1). This has been reduced to 60s in recent commit in master.","title":"Explanation"},{"location":"best-practice/worker-head-reconnection/#best-practice","text":"GCS HA feature #20498 is planned in Ray Core Roadmap. When this feature is released, expect a stable head and GCS such that worker-head connection lost issue will not appear anymore. Before that, to solve the workers-head connection lost, there are two options: Make head more stable: when creating the cluster, allocate sufficient amount of resources on head pod such that it tends to be stable and not easy to crash. You can also set {\"num-cpus\": \"0\"} in \"rayStartParams\" of \"headGroupSpec\" such that Ray scheduler will skip the head node when scheduling workloads. This also helps to maintain the stability of the head. Make reconnection shorter: for version <= 1.9.1, you can set this head param --system-config='{\"ping_gcs_rpc_server_max_retries\": 20}' to reduce the delay from 600s down to 20s before workers reconnect to the new head. Note: we should update this doc when GCS HA feature gets updated.","title":"Best Practice"},{"location":"components/apiserver/","text":"KubeRay APIServer \u00b6 KubeRay APIServer provides the gRPC and HTTP API to manage kuberay resources. Usage \u00b6 Compute Template \u00b6 Create compute templates in a given namespace \u00b6 POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"name\": \"default-template\", \"namespace\": \"<namespace>\", \"cpu\": 2, \"memory\": 4, \"gpu\": 1, \"gpuAccelerator\": \"Tesla-V100\" } List all compute templates in a given namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"compute_templates\": [ { \"name\": \"default-template\", \"namespace\": \"<namespace>\", \"cpu\": 2, \"memory\": 4, \"gpu\": 1, \"gpu_accelerator\": \"Tesla-V100\" } ] } List all compute templates in all namespaces \u00b6 GET {{baseUrl}}/apis/v1alpha2/compute_templates Get compute template by name \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name> Delete compute template by name \u00b6 DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name> Clusters \u00b6 Create cluster in a given namespace \u00b6 POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters payload { \"name\": \"test-cluster\", \"namespace\": \"<namespace>\", \"user\": \"jiaxin.shan\", \"version\": \"1.9.2\", \"environment\": \"DEV\", \"clusterSpec\": { \"headGroupSpec\": { \"computeTemplate\": \"head-template\", \"image\": \"ray.io/ray:1.9.2\", \"serviceType\": \"NodePort\", \"rayStartParams\": {} }, \"workerGroupSepc\": [ { \"groupName\": \"small-wg\", \"computeTemplate\": \"worker-template\", \"image\": \"ray.io/ray:1.9.2\", \"replicas\": 2, \"minReplicas\": 0, \"maxReplicas\": 5, \"rayStartParams\": {} } ] } } List all clusters in a given namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters { \"clusters\": [ { \"name\": \"test-cluster\", \"namespace\": \"<namespace>\", \"user\": \"jiaxin.shan\", \"version\": \"1.9.2\", \"environment\": \"DEV\", \"cluster_spec\": { \"head_group_spec\": { \"compute_template\": \"head-template\", \"image\": \"rayproject/ray:1.9.2\", \"service_type\": \"NodePort\", \"ray_start_params\": { \"dashboard-host\": \"0.0.0.0\", \"node-ip-address\": \"$MY_POD_IP\", \"port\": \"6379\" } }, \"worker_group_sepc\": [ { \"group_name\": \"small-wg\", \"compute_template\": \"worker-template\", \"image\": \"rayproject/ray:1.9.2\", \"replicas\": 2, \"min_replicas\": 0, \"max_replicas\": 5, \"ray_start_params\": { \"node-ip-address\": \"$MY_POD_IP\", } } ] }, \"created_at\": \"2022-03-13T15:13:09Z\", \"deleted_at\": null }, ] } List all clusters in all namespaces \u00b6 GET {{baseUrl}}/apis/v1alpha2/clusters Get cluster by its name and namespace \u00b6 GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name> Delete cluster by its name and namespace \u00b6 DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name>","title":"KubeRay ApiServer"},{"location":"components/apiserver/#kuberay-apiserver","text":"KubeRay APIServer provides the gRPC and HTTP API to manage kuberay resources.","title":"KubeRay APIServer"},{"location":"components/apiserver/#usage","text":"","title":"Usage"},{"location":"components/apiserver/#compute-template","text":"","title":"Compute Template"},{"location":"components/apiserver/#create-compute-templates-in-a-given-namespace","text":"POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"name\": \"default-template\", \"namespace\": \"<namespace>\", \"cpu\": 2, \"memory\": 4, \"gpu\": 1, \"gpuAccelerator\": \"Tesla-V100\" }","title":"Create compute templates in a given namespace"},{"location":"components/apiserver/#list-all-compute-templates-in-a-given-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates { \"compute_templates\": [ { \"name\": \"default-template\", \"namespace\": \"<namespace>\", \"cpu\": 2, \"memory\": 4, \"gpu\": 1, \"gpu_accelerator\": \"Tesla-V100\" } ] }","title":"List all compute templates in a given namespace"},{"location":"components/apiserver/#list-all-compute-templates-in-all-namespaces","text":"GET {{baseUrl}}/apis/v1alpha2/compute_templates","title":"List all compute templates in all namespaces"},{"location":"components/apiserver/#get-compute-template-by-name","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name>","title":"Get compute template by name"},{"location":"components/apiserver/#delete-compute-template-by-name","text":"DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/compute_templates/<compute_template_name>","title":"Delete compute template by name"},{"location":"components/apiserver/#clusters","text":"","title":"Clusters"},{"location":"components/apiserver/#create-cluster-in-a-given-namespace","text":"POST {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters payload { \"name\": \"test-cluster\", \"namespace\": \"<namespace>\", \"user\": \"jiaxin.shan\", \"version\": \"1.9.2\", \"environment\": \"DEV\", \"clusterSpec\": { \"headGroupSpec\": { \"computeTemplate\": \"head-template\", \"image\": \"ray.io/ray:1.9.2\", \"serviceType\": \"NodePort\", \"rayStartParams\": {} }, \"workerGroupSepc\": [ { \"groupName\": \"small-wg\", \"computeTemplate\": \"worker-template\", \"image\": \"ray.io/ray:1.9.2\", \"replicas\": 2, \"minReplicas\": 0, \"maxReplicas\": 5, \"rayStartParams\": {} } ] } }","title":"Create cluster in a given namespace"},{"location":"components/apiserver/#list-all-clusters-in-a-given-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters { \"clusters\": [ { \"name\": \"test-cluster\", \"namespace\": \"<namespace>\", \"user\": \"jiaxin.shan\", \"version\": \"1.9.2\", \"environment\": \"DEV\", \"cluster_spec\": { \"head_group_spec\": { \"compute_template\": \"head-template\", \"image\": \"rayproject/ray:1.9.2\", \"service_type\": \"NodePort\", \"ray_start_params\": { \"dashboard-host\": \"0.0.0.0\", \"node-ip-address\": \"$MY_POD_IP\", \"port\": \"6379\" } }, \"worker_group_sepc\": [ { \"group_name\": \"small-wg\", \"compute_template\": \"worker-template\", \"image\": \"rayproject/ray:1.9.2\", \"replicas\": 2, \"min_replicas\": 0, \"max_replicas\": 5, \"ray_start_params\": { \"node-ip-address\": \"$MY_POD_IP\", } } ] }, \"created_at\": \"2022-03-13T15:13:09Z\", \"deleted_at\": null }, ] }","title":"List all clusters in a given namespace"},{"location":"components/apiserver/#list-all-clusters-in-all-namespaces","text":"GET {{baseUrl}}/apis/v1alpha2/clusters","title":"List all clusters in all namespaces"},{"location":"components/apiserver/#get-cluster-by-its-name-and-namespace","text":"GET {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name>","title":"Get cluster by its name and namespace"},{"location":"components/apiserver/#delete-cluster-by-its-name-and-namespace","text":"DELETE {{baseUrl}}/apis/v1alpha2/namespaces/<namespace>/clusters/<cluster_name>","title":"Delete cluster by its name and namespace"},{"location":"components/cli/","text":"KubeRay CLI \u00b6 KubeRay CLI provides the ability to manage kuberay resources (ray clusters, compute templates etc) through command line interface. Installation \u00b6 Please check release page and download the binaries. Prerequisites \u00b6 Kuberay operator needs to be running. Kuberay apiserver needs to be running and accessible. Development \u00b6 Kuberay CLI uses Cobra framework for the CLI application. Kuberay CLI depends on kuberay apiserver to manage these resources by sending grpc requests to the kuberay apiserver. You can build kuberay binary following this way. cd kuberay/cli go build -o kuberay -a main.go Usage \u00b6 Configure kuberay apiserver endpoint \u00b6 Default kuberay apiserver endpoint: 127.0.0.1:8887 . If kuberay apiserver is not run locally, this must be set in order to manage ray clusters and ray compute templates. Read current kuberay apiserver endpoint \u00b6 ./kuberay config get endpoint Reset kuberay apiserver endpoint to default ( 127.0.0.1:8887 ) \u00b6 ./kuberay config reset endpoint Set kuberay apiserver endpoint \u00b6 ./kuberay config set endpoint <kuberay apiserver endpoint> Manage Ray Clusters \u00b6 Create a Ray Cluster \u00b6 Usage: kuberay cluster create [flags] Flags: --environment string environment of the cluster (valid values: DEV, TESTING, STAGING, PRODUCTION) (default \"DEV\") --head-compute-template string compute template name for ray head --head-image string ray head image --head-service-type string ray head service type (ClusterIP, NodePort, LoadBalancer) (default \"ClusterIP\") --name string name of the cluster -n, --namespace string kubernetes namespace where the cluster will be --user string SSO username of ray cluster creator --version string version of the ray cluster (default \"1.9.0\") --worker-compute-template string compute template name of worker in the first worker group --worker-group-name string first worker group name --worker-image string image of worker in the first worker group --worker-replicas uint32 pod replicas of workers in the first worker group (default 1) Known Limitation: Currently only one worker compute template is supported during creation. Get a Ray Cluster \u00b6 ./kuberay cluster get -n <namespace> <cluster name> List Ray Clusters \u00b6 ./kuberay cluster -n <namespace> list Delete a Ray Cluster \u00b6 ./kuberay cluster delete -n <namespace> <cluster name> Manage Ray Compute Template \u00b6 Create a Compute Template \u00b6 Usage: kuberay template compute create [flags] Flags: --cpu uint32 ray pod CPU (default 1) --gpu uint32 ray head GPU --gpu-accelerator string GPU Accelerator type --memory uint32 ray pod memory in GB (default 1) --name string name of the compute template -n, --namespace string kubernetes namespace where the compute template will be stored Get a Ray Compute Template \u00b6 ./kuberay template compute get -n <namespace> <compute template name> List Ray Compute Templates \u00b6 ./kuberay template compute list -n <namespace> Delete a Ray Compute Template \u00b6 ./kuberay template compute delete -n <namespace> <compute template name> End to end example \u00b6 Configure the endpoints kubectl port-forward svc/kuberay-apiserver-service 8887:8887 -n ray-system ./kuberay config set endpoint 127.0.0.1:8887 Create compute templates ./kuberay template compute create -n <namespace> --cpu 2 --memory 4 --name \"worker-template\" ./kuberay template compute create -n <namespace> --cpu 1 --memory 2 --name \"head-template\" List compute templates created ./kuberay template compute list Create the cluster ./kuberay cluster create -n <namespace> --name test-cluster --user jiaxin.shan \\ --head-compute-template head-template \\ --head-image rayproject/ray:1.9.2 \\ --worker-group-name small-wg \\ --worker-compute-template worker-template \\ --worker-image rayproject/ray:1.9.2 List the clusters ./kuberay cluster list","title":"KubeRay CLI"},{"location":"components/cli/#kuberay-cli","text":"KubeRay CLI provides the ability to manage kuberay resources (ray clusters, compute templates etc) through command line interface.","title":"KubeRay CLI"},{"location":"components/cli/#installation","text":"Please check release page and download the binaries.","title":"Installation"},{"location":"components/cli/#prerequisites","text":"Kuberay operator needs to be running. Kuberay apiserver needs to be running and accessible.","title":"Prerequisites"},{"location":"components/cli/#development","text":"Kuberay CLI uses Cobra framework for the CLI application. Kuberay CLI depends on kuberay apiserver to manage these resources by sending grpc requests to the kuberay apiserver. You can build kuberay binary following this way. cd kuberay/cli go build -o kuberay -a main.go","title":"Development"},{"location":"components/cli/#usage","text":"","title":"Usage"},{"location":"components/cli/#configure-kuberay-apiserver-endpoint","text":"Default kuberay apiserver endpoint: 127.0.0.1:8887 . If kuberay apiserver is not run locally, this must be set in order to manage ray clusters and ray compute templates.","title":"Configure kuberay apiserver endpoint"},{"location":"components/cli/#read-current-kuberay-apiserver-endpoint","text":"./kuberay config get endpoint","title":"Read current kuberay apiserver endpoint"},{"location":"components/cli/#reset-kuberay-apiserver-endpoint-to-default-1270018887","text":"./kuberay config reset endpoint","title":"Reset kuberay apiserver endpoint to default (127.0.0.1:8887)"},{"location":"components/cli/#set-kuberay-apiserver-endpoint","text":"./kuberay config set endpoint <kuberay apiserver endpoint>","title":"Set kuberay apiserver endpoint"},{"location":"components/cli/#manage-ray-clusters","text":"","title":"Manage Ray Clusters"},{"location":"components/cli/#create-a-ray-cluster","text":"Usage: kuberay cluster create [flags] Flags: --environment string environment of the cluster (valid values: DEV, TESTING, STAGING, PRODUCTION) (default \"DEV\") --head-compute-template string compute template name for ray head --head-image string ray head image --head-service-type string ray head service type (ClusterIP, NodePort, LoadBalancer) (default \"ClusterIP\") --name string name of the cluster -n, --namespace string kubernetes namespace where the cluster will be --user string SSO username of ray cluster creator --version string version of the ray cluster (default \"1.9.0\") --worker-compute-template string compute template name of worker in the first worker group --worker-group-name string first worker group name --worker-image string image of worker in the first worker group --worker-replicas uint32 pod replicas of workers in the first worker group (default 1) Known Limitation: Currently only one worker compute template is supported during creation.","title":"Create a Ray Cluster"},{"location":"components/cli/#get-a-ray-cluster","text":"./kuberay cluster get -n <namespace> <cluster name>","title":"Get a Ray Cluster"},{"location":"components/cli/#list-ray-clusters","text":"./kuberay cluster -n <namespace> list","title":"List Ray Clusters"},{"location":"components/cli/#delete-a-ray-cluster","text":"./kuberay cluster delete -n <namespace> <cluster name>","title":"Delete a Ray Cluster"},{"location":"components/cli/#manage-ray-compute-template","text":"","title":"Manage Ray Compute Template"},{"location":"components/cli/#create-a-compute-template","text":"Usage: kuberay template compute create [flags] Flags: --cpu uint32 ray pod CPU (default 1) --gpu uint32 ray head GPU --gpu-accelerator string GPU Accelerator type --memory uint32 ray pod memory in GB (default 1) --name string name of the compute template -n, --namespace string kubernetes namespace where the compute template will be stored","title":"Create a Compute Template"},{"location":"components/cli/#get-a-ray-compute-template","text":"./kuberay template compute get -n <namespace> <compute template name>","title":"Get a Ray Compute Template"},{"location":"components/cli/#list-ray-compute-templates","text":"./kuberay template compute list -n <namespace>","title":"List Ray Compute Templates"},{"location":"components/cli/#delete-a-ray-compute-template","text":"./kuberay template compute delete -n <namespace> <compute template name>","title":"Delete a Ray Compute Template"},{"location":"components/cli/#end-to-end-example","text":"Configure the endpoints kubectl port-forward svc/kuberay-apiserver-service 8887:8887 -n ray-system ./kuberay config set endpoint 127.0.0.1:8887 Create compute templates ./kuberay template compute create -n <namespace> --cpu 2 --memory 4 --name \"worker-template\" ./kuberay template compute create -n <namespace> --cpu 1 --memory 2 --name \"head-template\" List compute templates created ./kuberay template compute list Create the cluster ./kuberay cluster create -n <namespace> --name test-cluster --user jiaxin.shan \\ --head-compute-template head-template \\ --head-image rayproject/ray:1.9.2 \\ --worker-group-name small-wg \\ --worker-compute-template worker-template \\ --worker-image rayproject/ray:1.9.2 List the clusters ./kuberay cluster list","title":"End to end example"},{"location":"components/operator/","text":"Ray Kubernetes Operator \u00b6 KubeRay operator makes deploying and managing Ray clusters on top of Kubernetes painless - clusters are defined as a custom RayCluster resource and managed by a fault-tolerant Ray controller. The Ray Operator is a Kubernetes operator to automate provisioning, management, autoscaling and operations of Ray clusters deployed to Kubernetes. Some of the main features of the operator are: - Management of first-class RayClusters via a custom resource . - Support for heterogenous worker types in a single Ray cluster. - Built-in monitoring via Prometheus. - Use of PodTemplate to create Ray pods - Updated status based on the running pods - Events added to the RayCluster instance - Automatically populate environment variables in the containers - Automatically prefix your container command with the ray start command - Automatically adding the volumeMount at /dev/shm for shared memory - Use of ScaleStartegy to remove specific nodes in specific groups Overview \u00b6 When deployed, the ray operator will watch for K8s events (create/delete/update) for the raycluster resources. The ray operator can create a raycluster (head + multipe workers), delete a cluster, or update the cluster by adding or removing worker pods. Ray cluster creation \u00b6 Once a raycluster resource is created, the operator will configure and create the ray-head and the ray-workers specified in the raycluster manifest as shown below. Ray cluster Update \u00b6 You can update the number of replicas in a worker goup, and specify which exact replica to remove by updated the raycluster resource manifest: Ray cluster example code \u00b6 An example ray code is defined in this configmap that is mounted into the ray head-pod. By examining the logs of the head pod, we can see the list of the IP addresses of the nodes that joined the ray cluster: Deploy the operator \u00b6 kubectl apply -k \"github.com/ray-project/kuberay/ray-operator/config/default\" Check that the controller is running. $ kubectl get deployments -n ray-system NAME READY UP-TO-DATE AVAILABLE AGE ray-operator 1 /1 1 1 40s $ kubectl get pods -n ray-system NAME READY STATUS RESTARTS AGE ray-operator-75dbbf8587-5lrvn 1 /1 Running 0 31s Delete the operator kubectl delete -k \"github.com/ray-project/kuberay/ray-operator/config/default\" Running an example cluster \u00b6 There are three example config files to deploy RayClusters included here: Sample Description ray-cluster.mini.yaml Small example consisting of 1 head pod. ray-cluster.heterogeneous.yaml Example with heterogenous worker types. 1 head pod and 2 worker pods, each of which has a different resource quota. ray-cluster.complete.yaml Shows all available custom resouce properties. # Create a configmap with a hello world Ray code. kubectl create -f config/samples/config-map-ray-code.yaml configmap/ray-code created # Create a cluster. $ kubectl create -f config/samples/ray-cluster.heterogeneous.yaml raycluster.ray.io/raycluster-heterogeneous created # List running clusters. $ kubectl get rayclusters NAME AGE raycluster-heterogeneous 2m48s # The created cluster should include a head pod, worker pod, and a head service. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-heterogeneous-head-5r6qr 1 /1 Running 0 14m raycluster-heterogeneous-worker-medium-group-ljzzt 1 /1 Running 0 14m raycluster-heterogeneous-worker-small-group-76qxb 1 /1 Running 0 14m raycluster-heterogeneous-worker-small-group-dcl4d 1 /1 Running 0 14m $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .152.183.1 <none> 443 /TCP 35d raycluster-heterogeneous-my-svc ClusterIP None <none> 80 /TCP 15m The logs of the head pod should show 4 nodes in the Ray cluster Ray Nodes: {'10.1.73.139', '10.1.73.138', '10.1.73.140', '10.1.73.141'} # check the logs of the head pod $ kubectl logs raycluster-heterogeneous-head-5r6qr 2020 -11-18 09 :23:32,069 INFO services.py:1092 -- View the Ray dashboard at http://10.1.73.141:8265 2020 -11-18 09 :23:31,668 INFO scripts.py:467 -- Local node IP: 10 .1.73.141 2020 -11-18 09 :23:32,093 SUCC scripts.py:497 -- -------------------- 2020 -11-18 09 :23:32,093 SUCC scripts.py:498 -- Ray runtime started. 2020 -11-18 09 :23:32,093 SUCC scripts.py:499 -- -------------------- 2020 -11-18 09 :23:32,093 INFO scripts.py:501 -- Next steps 2020 -11-18 09 :23:32,093 INFO scripts.py:503 -- To connect to this Ray runtime from another node, run 2020 -11-18 09 :23:32,093 INFO scripts.py:507 -- ray start --address = '10.1.73.141:6379' --redis-password = 'LetMeInRay' 2020 -11-18 09 :23:32,093 INFO scripts.py:509 -- Alternatively, use the following Python code: 2020 -11-18 09 :23:32,093 INFO scripts.py:512 -- import ray 2020 -11-18 09 :23:32,093 INFO scripts.py:519 -- ray.init ( address = 'auto' , _redis_password = 'LetMeInRay' ) 2020 -11-18 09 :23:32,093 INFO scripts.py:522 -- If connection fails, check your firewall settings and network configuration. 2020 -11-18 09 :23:32,093 INFO scripts.py:526 -- To terminate the Ray runtime, run 2020 -11-18 09 :23:32,094 INFO scripts.py:527 -- ray stop 2020 -11-18 09 :23:32,656 INFO worker.py:651 -- Connecting to existing Ray cluster at address: 10 .1.73.141:6379 2020 -11-18 09 :23:32,669 WARNING services.py:202 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node? trying to connect to Ray! now executing some code with Ray! Ray Nodes: { '10.1.73.139' , '10.1.73.138' , '10.1.73.140' , '10.1.73.141' } Execution time = 6 .961702346801758 # Delete the cluster. $ kubectl delete raycluster raycluster-heterogeneous","title":"KubeRay Operator"},{"location":"components/operator/#ray-kubernetes-operator","text":"KubeRay operator makes deploying and managing Ray clusters on top of Kubernetes painless - clusters are defined as a custom RayCluster resource and managed by a fault-tolerant Ray controller. The Ray Operator is a Kubernetes operator to automate provisioning, management, autoscaling and operations of Ray clusters deployed to Kubernetes. Some of the main features of the operator are: - Management of first-class RayClusters via a custom resource . - Support for heterogenous worker types in a single Ray cluster. - Built-in monitoring via Prometheus. - Use of PodTemplate to create Ray pods - Updated status based on the running pods - Events added to the RayCluster instance - Automatically populate environment variables in the containers - Automatically prefix your container command with the ray start command - Automatically adding the volumeMount at /dev/shm for shared memory - Use of ScaleStartegy to remove specific nodes in specific groups","title":"Ray Kubernetes Operator"},{"location":"components/operator/#overview","text":"When deployed, the ray operator will watch for K8s events (create/delete/update) for the raycluster resources. The ray operator can create a raycluster (head + multipe workers), delete a cluster, or update the cluster by adding or removing worker pods.","title":"Overview"},{"location":"components/operator/#ray-cluster-creation","text":"Once a raycluster resource is created, the operator will configure and create the ray-head and the ray-workers specified in the raycluster manifest as shown below.","title":"Ray cluster creation"},{"location":"components/operator/#ray-cluster-update","text":"You can update the number of replicas in a worker goup, and specify which exact replica to remove by updated the raycluster resource manifest:","title":"Ray cluster Update"},{"location":"components/operator/#ray-cluster-example-code","text":"An example ray code is defined in this configmap that is mounted into the ray head-pod. By examining the logs of the head pod, we can see the list of the IP addresses of the nodes that joined the ray cluster:","title":"Ray cluster example code"},{"location":"components/operator/#deploy-the-operator","text":"kubectl apply -k \"github.com/ray-project/kuberay/ray-operator/config/default\" Check that the controller is running. $ kubectl get deployments -n ray-system NAME READY UP-TO-DATE AVAILABLE AGE ray-operator 1 /1 1 1 40s $ kubectl get pods -n ray-system NAME READY STATUS RESTARTS AGE ray-operator-75dbbf8587-5lrvn 1 /1 Running 0 31s Delete the operator kubectl delete -k \"github.com/ray-project/kuberay/ray-operator/config/default\"","title":"Deploy the operator"},{"location":"components/operator/#running-an-example-cluster","text":"There are three example config files to deploy RayClusters included here: Sample Description ray-cluster.mini.yaml Small example consisting of 1 head pod. ray-cluster.heterogeneous.yaml Example with heterogenous worker types. 1 head pod and 2 worker pods, each of which has a different resource quota. ray-cluster.complete.yaml Shows all available custom resouce properties. # Create a configmap with a hello world Ray code. kubectl create -f config/samples/config-map-ray-code.yaml configmap/ray-code created # Create a cluster. $ kubectl create -f config/samples/ray-cluster.heterogeneous.yaml raycluster.ray.io/raycluster-heterogeneous created # List running clusters. $ kubectl get rayclusters NAME AGE raycluster-heterogeneous 2m48s # The created cluster should include a head pod, worker pod, and a head service. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-heterogeneous-head-5r6qr 1 /1 Running 0 14m raycluster-heterogeneous-worker-medium-group-ljzzt 1 /1 Running 0 14m raycluster-heterogeneous-worker-small-group-76qxb 1 /1 Running 0 14m raycluster-heterogeneous-worker-small-group-dcl4d 1 /1 Running 0 14m $ kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .152.183.1 <none> 443 /TCP 35d raycluster-heterogeneous-my-svc ClusterIP None <none> 80 /TCP 15m The logs of the head pod should show 4 nodes in the Ray cluster Ray Nodes: {'10.1.73.139', '10.1.73.138', '10.1.73.140', '10.1.73.141'} # check the logs of the head pod $ kubectl logs raycluster-heterogeneous-head-5r6qr 2020 -11-18 09 :23:32,069 INFO services.py:1092 -- View the Ray dashboard at http://10.1.73.141:8265 2020 -11-18 09 :23:31,668 INFO scripts.py:467 -- Local node IP: 10 .1.73.141 2020 -11-18 09 :23:32,093 SUCC scripts.py:497 -- -------------------- 2020 -11-18 09 :23:32,093 SUCC scripts.py:498 -- Ray runtime started. 2020 -11-18 09 :23:32,093 SUCC scripts.py:499 -- -------------------- 2020 -11-18 09 :23:32,093 INFO scripts.py:501 -- Next steps 2020 -11-18 09 :23:32,093 INFO scripts.py:503 -- To connect to this Ray runtime from another node, run 2020 -11-18 09 :23:32,093 INFO scripts.py:507 -- ray start --address = '10.1.73.141:6379' --redis-password = 'LetMeInRay' 2020 -11-18 09 :23:32,093 INFO scripts.py:509 -- Alternatively, use the following Python code: 2020 -11-18 09 :23:32,093 INFO scripts.py:512 -- import ray 2020 -11-18 09 :23:32,093 INFO scripts.py:519 -- ray.init ( address = 'auto' , _redis_password = 'LetMeInRay' ) 2020 -11-18 09 :23:32,093 INFO scripts.py:522 -- If connection fails, check your firewall settings and network configuration. 2020 -11-18 09 :23:32,093 INFO scripts.py:526 -- To terminate the Ray runtime, run 2020 -11-18 09 :23:32,094 INFO scripts.py:527 -- ray stop 2020 -11-18 09 :23:32,656 INFO worker.py:651 -- Connecting to existing Ray cluster at address: 10 .1.73.141:6379 2020 -11-18 09 :23:32,669 WARNING services.py:202 -- Some processes that the driver needs to connect to have not registered with Redis, so retrying. Have you run 'ray start' on this node? trying to connect to Ray! now executing some code with Ray! Ray Nodes: { '10.1.73.139' , '10.1.73.138' , '10.1.73.140' , '10.1.73.141' } Execution time = 6 .961702346801758 # Delete the cluster. $ kubectl delete raycluster raycluster-heterogeneous","title":"Running an example cluster"},{"location":"deploy/helm-cluster/","text":"Ray Cluster \u00b6 Make sure ray-operator has been deployed. Ray is an open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library. Helm \u00b6 $ helm version version.BuildInfo{Version:\"v3.6.2\", GitCommit:\"ee407bdf364942bcb8e8c665f82e15aa28009b71\", GitTreeState:\"dirty\", GoVersion:\"go1.16.5\"} TL;DR; \u00b6 $ helm install ray-cluster --namespace ray-system --create-namespace https://github.com/ray-project/kuberay/releases/download/v0.3.0/helm-chart-ray-cluster-0.1.0.tgz Installing the Chart \u00b6 To install the chart with the release name my-release : $ helm install my-release --namespace ray-system --create-namespace https://github.com/ray-project/kuberay/releases/download/v0.3.0/helm-chart-ray-cluster-0.1.0.tgz note: The chart will submit a RayCluster. Uninstalling the Chart \u00b6 To uninstall/delete the my-release deployment: helm delete my-release -n ray-system The command removes nearly all the Kubernetes components associated with the chart and deletes the release. Check Cluster status \u00b6 Get Service \u00b6 $ kubectl get svc -l ray.io/cluster = ray-cluster NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ray-cluster-head-svc ClusterIP 10.103.36.68 <none> 10001/TCP,6379/TCP,8265/TCP 9m24s Forward to dashboard \u00b6 $ kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES ray-cluster-head-sd77l 1/1 Running 0 8h 10.1.61.208 docker-desktop <none> <none> ray-cluster-worker-workergroup-czxd6 1/1 Running 0 8h 10.1.61.207 docker-desktop <none> <none> kuberay-operator-687785b964-jgfhv 1/1 Running 6 3d4h 10.1.61.196 docker-desktop <none> <none> $ kubectl port-forward ray-cluster-head-sd77l 8265 Forwarding from 127.0.0.1:8265 -> 8265 Forwarding from [::1]:8265 -> 8265","title":"Installation(Helm-cluster)"},{"location":"deploy/helm-cluster/#ray-cluster","text":"Make sure ray-operator has been deployed. Ray is an open source framework that provides a simple, universal API for building distributed applications. Ray is packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library.","title":"Ray Cluster"},{"location":"deploy/helm-cluster/#helm","text":"$ helm version version.BuildInfo{Version:\"v3.6.2\", GitCommit:\"ee407bdf364942bcb8e8c665f82e15aa28009b71\", GitTreeState:\"dirty\", GoVersion:\"go1.16.5\"}","title":"Helm"},{"location":"deploy/helm-cluster/#tldr","text":"$ helm install ray-cluster --namespace ray-system --create-namespace https://github.com/ray-project/kuberay/releases/download/v0.3.0/helm-chart-ray-cluster-0.1.0.tgz","title":"TL;DR;"},{"location":"deploy/helm-cluster/#installing-the-chart","text":"To install the chart with the release name my-release : $ helm install my-release --namespace ray-system --create-namespace https://github.com/ray-project/kuberay/releases/download/v0.3.0/helm-chart-ray-cluster-0.1.0.tgz note: The chart will submit a RayCluster.","title":"Installing the Chart"},{"location":"deploy/helm-cluster/#uninstalling-the-chart","text":"To uninstall/delete the my-release deployment: helm delete my-release -n ray-system The command removes nearly all the Kubernetes components associated with the chart and deletes the release.","title":"Uninstalling the Chart"},{"location":"deploy/helm-cluster/#check-cluster-status","text":"","title":"Check Cluster status"},{"location":"deploy/helm-cluster/#get-service","text":"$ kubectl get svc -l ray.io/cluster = ray-cluster NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ray-cluster-head-svc ClusterIP 10.103.36.68 <none> 10001/TCP,6379/TCP,8265/TCP 9m24s","title":"Get Service"},{"location":"deploy/helm-cluster/#forward-to-dashboard","text":"$ kubectl get pod -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES ray-cluster-head-sd77l 1/1 Running 0 8h 10.1.61.208 docker-desktop <none> <none> ray-cluster-worker-workergroup-czxd6 1/1 Running 0 8h 10.1.61.207 docker-desktop <none> <none> kuberay-operator-687785b964-jgfhv 1/1 Running 6 3d4h 10.1.61.196 docker-desktop <none> <none> $ kubectl port-forward ray-cluster-head-sd77l 8265 Forwarding from 127.0.0.1:8265 -> 8265 Forwarding from [::1]:8265 -> 8265","title":"Forward to dashboard"},{"location":"deploy/helm/","text":"KubeRay Operator \u00b6 Kuberay-operator: A simple Helm chart Run a deployment of Ray Operator. Deploy ray operator first, then deploy ray cluster. Helm \u00b6 Make sure helm version is v3+ $ helm version version.BuildInfo{Version:\"v3.6.2\", GitCommit:\"ee407bdf364942bcb8e8c665f82e15aa28009b71\", GitTreeState:\"dirty\", GoVersion:\"go1.16.5\"} Installing the Chart \u00b6 To avoid duplicate CRD definitions in this repo, we reuse CRD config in ray-operator : $ kubectl apply -k \"github.com/ray-project/kuberay/ray-operator/config/crd?ref=v0.3.0\" Please use command below: $ helm install kuberay-operator --namespace ray-system --create-namespace $( curl -s https://api.github.com/repos/ray-project/kuberay/releases/latest | grep '\"browser_download_url\":' | sort | grep -om1 'https.*helm-chart-kuberay-operator.*tgz' ) List the Chart \u00b6 To list the my-release deployment: $ helm list -n kuberay-operator Uninstalling the Chart \u00b6 To uninstall/delete the my-release deployment: $ helm delete kuberay-operator -n ray-system The command removes nearly all the Kubernetes components associated with the chart and deletes the release.","title":"Installation(Helm)"},{"location":"deploy/helm/#kuberay-operator","text":"Kuberay-operator: A simple Helm chart Run a deployment of Ray Operator. Deploy ray operator first, then deploy ray cluster.","title":"KubeRay Operator"},{"location":"deploy/helm/#helm","text":"Make sure helm version is v3+ $ helm version version.BuildInfo{Version:\"v3.6.2\", GitCommit:\"ee407bdf364942bcb8e8c665f82e15aa28009b71\", GitTreeState:\"dirty\", GoVersion:\"go1.16.5\"}","title":"Helm"},{"location":"deploy/helm/#installing-the-chart","text":"To avoid duplicate CRD definitions in this repo, we reuse CRD config in ray-operator : $ kubectl apply -k \"github.com/ray-project/kuberay/ray-operator/config/crd?ref=v0.3.0\" Please use command below: $ helm install kuberay-operator --namespace ray-system --create-namespace $( curl -s https://api.github.com/repos/ray-project/kuberay/releases/latest | grep '\"browser_download_url\":' | sort | grep -om1 'https.*helm-chart-kuberay-operator.*tgz' )","title":"Installing the Chart"},{"location":"deploy/helm/#list-the-chart","text":"To list the my-release deployment: $ helm list -n kuberay-operator","title":"List the Chart"},{"location":"deploy/helm/#uninstalling-the-chart","text":"To uninstall/delete the my-release deployment: $ helm delete kuberay-operator -n ray-system The command removes nearly all the Kubernetes components associated with the chart and deletes the release.","title":"Uninstalling the Chart"},{"location":"deploy/installation/","text":"Installation \u00b6 Nightly version \u00b6 kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources\" kubectl apply -k \"github.com/ray-project/kuberay/manifests/base\" Stable version \u00b6 kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources?ref=v0.2.0\" kubectl apply -k \"github.com/ray-project/kuberay/manifests/base?ref=v0.2.0\" Observe that we must use kubectl create to install cluster-scoped resources. The corresponding kubectl apply command will not work. See KubeRay issue #271 .","title":"Installation(Yaml)"},{"location":"deploy/installation/#installation","text":"","title":"Installation"},{"location":"deploy/installation/#nightly-version","text":"kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources\" kubectl apply -k \"github.com/ray-project/kuberay/manifests/base\"","title":"Nightly version"},{"location":"deploy/installation/#stable-version","text":"kubectl create -k \"github.com/ray-project/kuberay/manifests/cluster-scope-resources?ref=v0.2.0\" kubectl apply -k \"github.com/ray-project/kuberay/manifests/base?ref=v0.2.0\" Observe that we must use kubectl create to install cluster-scoped resources. The corresponding kubectl apply command will not work. See KubeRay issue #271 .","title":"Stable version"},{"location":"design/protobuf-grpc-service/","text":"Support proto Core API and RESTful backend services \u00b6 Motivation \u00b6 There're few major blockers for users to use KubeRay Operator directly. Current ray operator is only friendly to users who is familiar with Kubernetes operator pattern. For most data scientists, there's still a learning curve. Using kubectl requires sophisticated permission system. Some kubernetes clusters do not enable user level authentication. In some companies, devops use loose RBAC management and corp SSO system is not integrated with Kubernetes OIDC at all. Due to above reason, it's worth to build generic abstraction on top of RayCluster CRD. With the core api support, we can easily build backend services, cli, etc to bridge users without Kubernetes experiences to KubeRay. Goals \u00b6 The api definition should be flexible enough to support different kinds of clients (e.g. backend, cli etc). This backend service underneath should leverage generate clients to interact with existing RayCluster custom resources. New added components should be plugable to existing operator. Proposal \u00b6 Deployment topology and interactive flow \u00b6 The new gRPC service would be a individual deployment of the KubeRay control plane and user can choose to install it optionally. It will create a service and exposes endpoint to users. NAME READY STATUS RESTARTS AGE kuberay-grpc-service-c8db9dc65-d4w5r 1/1 Running 0 2d15h kuberay-operator-785476b948-fmlm7 1/1 Running 0 3d In issue #29 , RayCluster CRD clientset has been generated and gRPC service can leverage it to operate Custom Resources. A simple flow would be like this. (Thanks @akanso for providing the flow) client --> GRPC Server --> [created Custom Resources] <-- Ray Operator (reads CR and accordingly performs CRUD) API abstraction \u00b6 Protocol Buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Protoc also provides different community plugins to meet different needs. In order to better define resources at the API level, a few proto files will be defined. Technically, we can use similar data structure like RayCluster Kubernetes resource but this is probably not a good idea. Some of the Kubernetes API like tolerance and node affinity are too complicated to be converted to an API. We want to leave some flexibility to use database to store history data in the near future (for example, pagination, list options etc). We end up propsing a simple and easy API which can cover most of the daily requirements. message Cluster { // Required input field. Unique Cluster name provided by user. string name = 1; // Required input field. Cluster's namespace provided by user string namespace = 2; // Required field. This field indicates the user who owns the cluster. string user = 3; // Optional input field. Ray cluster version string version = 4; // Optional field. enum Environment { DEV = 0; TESTING = 1; STAGING = 2; PRODUCTION = 3; } Environment environment = 5; // Required field. This field indicates ray cluster configuration ClusterSpec cluster_spec = 6; // Output. The time that the Cluster created. google.protobuf.Timestamp created_at = 7; // Output. The time that the Cluster deleted. google.protobuf.Timestamp deleted_at = 8; } message ClusterSpec { // The head group configuration HeadGroupSpec head_group_spec = 1; // The worker group configurations repeated WorkerGroupSpec worker_group_sepc = 2; } message HeadGroupSpec { // Optional. The computeTemplate of head node group string compute_template = 1; // Optional field. This field will be used to retrieve right ray container string image = 2; // Optional. The service type (ClusterIP, NodePort, Load balancer) of the head node string service_type = 3; // Optional. The ray start parames of head node group map<string, string> ray_start_params = 4; } message WorkerGroupSpec { // Required. Group name of the current worker group string group_name = 1; // Optional. The computeTemplate of head node group string compute_template = 2; // Optional field. This field will be used to retrieve right ray container string image = 3; // Required. Desired replicas of the worker group int32 replicas = 4; // Optional. Min replicas of the worker group int32 min_replicas = 5; // Optional. Max replicas of the worker group int32 max_replicas = 6; // Optional. The ray start parames of worker node group map<string, string> ray_start_params = 7; } // ComputeTemplate can be reused by any compute units like worker group, workspace, image build job, etc message ComputeTemplate { // The ID of the compute template string name = 1; // Number of cpus uint32 cpu = 2; // Number of memory uint32 memory = 3; // Number of gpus uint32 gpu = 4; // The detail gpu accelerator type string gpu_accelerator = 5; } // ImageTemplate can be used by worker group and workspce. // They can be distinguish by different entrypoints message ImageTemplate { // The ID of the image template string name = 1; // The base container image to be used for image building string base_image = 2; // The pip packages to install repeated string pip_packages = 3; // The conda packages to install repeated string conda_packages = 4; // The system packages to install repeated string system_packages = 5; // The environment variables to set map<string, string> environment_variables = 6; // The post install commands to execute string custom_commands = 7; // Output. The result image generated string image = 9; } Support multiple clients \u00b6 Since we may have different clients to interactive with our services, we will generate gateway RESTful APIs and OpenAPI Spec at the same time. .proto define core api, grpc and gateway services. go_client and swagger can be generated easily for further usage. gRPC services \u00b6 The GRPC protocol provides an extremely efficient way of cross-service communication for distributed applications. The public toolkit includes instruments to generate client and server code-bases for many languages allowing the developer to use the most optimal language for the task. The service will implement gPRC server as following graph shows. A ResourceManager will be used to abstract the implementation of CRUD operators. ClientManager manages kubernetes clients which can operate Kubernetes native resource and custom resources like RayCluster. RayClusterClient comes from code generator of CRD. issue#29 Implementation History \u00b6 2021-11-25: inital proposal accepted. Note: we should update doc when there's a large update.","title":"Core API and Backend Service"},{"location":"design/protobuf-grpc-service/#support-proto-core-api-and-restful-backend-services","text":"","title":"Support proto Core API and RESTful backend services"},{"location":"design/protobuf-grpc-service/#motivation","text":"There're few major blockers for users to use KubeRay Operator directly. Current ray operator is only friendly to users who is familiar with Kubernetes operator pattern. For most data scientists, there's still a learning curve. Using kubectl requires sophisticated permission system. Some kubernetes clusters do not enable user level authentication. In some companies, devops use loose RBAC management and corp SSO system is not integrated with Kubernetes OIDC at all. Due to above reason, it's worth to build generic abstraction on top of RayCluster CRD. With the core api support, we can easily build backend services, cli, etc to bridge users without Kubernetes experiences to KubeRay.","title":"Motivation"},{"location":"design/protobuf-grpc-service/#goals","text":"The api definition should be flexible enough to support different kinds of clients (e.g. backend, cli etc). This backend service underneath should leverage generate clients to interact with existing RayCluster custom resources. New added components should be plugable to existing operator.","title":"Goals"},{"location":"design/protobuf-grpc-service/#proposal","text":"","title":"Proposal"},{"location":"design/protobuf-grpc-service/#deployment-topology-and-interactive-flow","text":"The new gRPC service would be a individual deployment of the KubeRay control plane and user can choose to install it optionally. It will create a service and exposes endpoint to users. NAME READY STATUS RESTARTS AGE kuberay-grpc-service-c8db9dc65-d4w5r 1/1 Running 0 2d15h kuberay-operator-785476b948-fmlm7 1/1 Running 0 3d In issue #29 , RayCluster CRD clientset has been generated and gRPC service can leverage it to operate Custom Resources. A simple flow would be like this. (Thanks @akanso for providing the flow) client --> GRPC Server --> [created Custom Resources] <-- Ray Operator (reads CR and accordingly performs CRUD)","title":"Deployment topology and interactive flow"},{"location":"design/protobuf-grpc-service/#api-abstraction","text":"Protocol Buffers are a language-neutral, platform-neutral extensible mechanism for serializing structured data. Protoc also provides different community plugins to meet different needs. In order to better define resources at the API level, a few proto files will be defined. Technically, we can use similar data structure like RayCluster Kubernetes resource but this is probably not a good idea. Some of the Kubernetes API like tolerance and node affinity are too complicated to be converted to an API. We want to leave some flexibility to use database to store history data in the near future (for example, pagination, list options etc). We end up propsing a simple and easy API which can cover most of the daily requirements. message Cluster { // Required input field. Unique Cluster name provided by user. string name = 1; // Required input field. Cluster's namespace provided by user string namespace = 2; // Required field. This field indicates the user who owns the cluster. string user = 3; // Optional input field. Ray cluster version string version = 4; // Optional field. enum Environment { DEV = 0; TESTING = 1; STAGING = 2; PRODUCTION = 3; } Environment environment = 5; // Required field. This field indicates ray cluster configuration ClusterSpec cluster_spec = 6; // Output. The time that the Cluster created. google.protobuf.Timestamp created_at = 7; // Output. The time that the Cluster deleted. google.protobuf.Timestamp deleted_at = 8; } message ClusterSpec { // The head group configuration HeadGroupSpec head_group_spec = 1; // The worker group configurations repeated WorkerGroupSpec worker_group_sepc = 2; } message HeadGroupSpec { // Optional. The computeTemplate of head node group string compute_template = 1; // Optional field. This field will be used to retrieve right ray container string image = 2; // Optional. The service type (ClusterIP, NodePort, Load balancer) of the head node string service_type = 3; // Optional. The ray start parames of head node group map<string, string> ray_start_params = 4; } message WorkerGroupSpec { // Required. Group name of the current worker group string group_name = 1; // Optional. The computeTemplate of head node group string compute_template = 2; // Optional field. This field will be used to retrieve right ray container string image = 3; // Required. Desired replicas of the worker group int32 replicas = 4; // Optional. Min replicas of the worker group int32 min_replicas = 5; // Optional. Max replicas of the worker group int32 max_replicas = 6; // Optional. The ray start parames of worker node group map<string, string> ray_start_params = 7; } // ComputeTemplate can be reused by any compute units like worker group, workspace, image build job, etc message ComputeTemplate { // The ID of the compute template string name = 1; // Number of cpus uint32 cpu = 2; // Number of memory uint32 memory = 3; // Number of gpus uint32 gpu = 4; // The detail gpu accelerator type string gpu_accelerator = 5; } // ImageTemplate can be used by worker group and workspce. // They can be distinguish by different entrypoints message ImageTemplate { // The ID of the image template string name = 1; // The base container image to be used for image building string base_image = 2; // The pip packages to install repeated string pip_packages = 3; // The conda packages to install repeated string conda_packages = 4; // The system packages to install repeated string system_packages = 5; // The environment variables to set map<string, string> environment_variables = 6; // The post install commands to execute string custom_commands = 7; // Output. The result image generated string image = 9; }","title":"API abstraction"},{"location":"design/protobuf-grpc-service/#support-multiple-clients","text":"Since we may have different clients to interactive with our services, we will generate gateway RESTful APIs and OpenAPI Spec at the same time. .proto define core api, grpc and gateway services. go_client and swagger can be generated easily for further usage.","title":"Support multiple clients"},{"location":"design/protobuf-grpc-service/#grpc-services","text":"The GRPC protocol provides an extremely efficient way of cross-service communication for distributed applications. The public toolkit includes instruments to generate client and server code-bases for many languages allowing the developer to use the most optimal language for the task. The service will implement gPRC server as following graph shows. A ResourceManager will be used to abstract the implementation of CRUD operators. ClientManager manages kubernetes clients which can operate Kubernetes native resource and custom resources like RayCluster. RayClusterClient comes from code generator of CRD. issue#29","title":"gRPC services"},{"location":"design/protobuf-grpc-service/#implementation-history","text":"2021-11-25: inital proposal accepted. Note: we should update doc when there's a large update.","title":"Implementation History"},{"location":"guidance/autoscaler/","text":"Autoscaler (Experimental) \u00b6 Note: This feature is still experimental, there're few limitations and stabilization will be done in future release from both Ray and KubeRay side. Prerequisite \u00b6 You have to use nightly operator images because autoscaler support is merged recently. You can follow below steps for a quick deployment. git clone https://github.com/ray-project/kuberay.git cd kuberay kubectl create -k manifests/cluster-scope-resources kubectl apply -k manifests/overlays/autoscaling Note: For compatibility with the Ray autoscaler, the KubeRay Operator's entrypoint must include the flag --prioritize-workers-to-delete . The kustomization overlay manifests/overlays/autoscaling provided in the last command above adds the necessary flag. Deploy a cluster with autoscaling enabled \u00b6 kubectl apply -f ray-operator/config/samples/ray-cluster.autoscaler.yaml To verify autoscaler is working, Do not trust READY container status because autoscaler container has in-built retry and even there's error, it won't crash now. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-head-mgwwk 2/2 Running 0 4m41s The recommended way is to check containers logs. Here's an example of well-behaved autoscaler. kubectl logs -f raycluster-autoscaler-head-mgwwk autoscaler 2022-03-10 07:51:22,616 INFO monitor.py:226 -- Starting autoscaler metrics server on port 44217 2022-03-10 07:51:22,621 INFO monitor.py:243 -- Monitor: Started 2022-03-10 07:51:22,824 INFO node_provider.py:143 -- Creating KuberayNodeProvider. 2022-03-10 07:51:22,825 INFO autoscaler.py:282 -- StandardAutoscaler: {'provider': {'type': 'kuberay', 'namespace': 'default', 'disable_node_updaters': True, 'disable_launch_config_check': True}, 'cluster_name': 'raycluster-autoscaler', 'head_node_type': 'head-group', 'available_node_types': {'head-group': {'min_workers': 0, 'max_workers': 0, 'node_config': {}, 'resources': {'CPU': 1}}, 'small-group': {'min_workers': 1, 'max_workers': 300, 'node_config': {}, 'resources': {'CPU': 1}}}, 'max_workers': 300, 'idle_timeout_minutes': 5, 'upscaling_speed': 1, 'file_mounts': {}, 'cluster_synced_files': [], 'file_mounts_sync_continuously': False, 'initialization_commands': [], 'setup_commands': [], 'head_setup_commands': [], 'worker_setup_commands': [], 'head_start_ray_commands': [], 'worker_start_ray_commands': [], 'auth': {}, 'head_node': {}, 'worker_nodes': {}} 2022-03-10 07:51:23,027 INFO autoscaler.py:327 -- ======== Autoscaler status: 2022-03-10 07:51:23.027271 ======== Node status --------------------------------------------------------------- Healthy: 1 head-group Pending: (no pending nodes) Recent failures: (no failures) Resources --------------------------------------------------------------- Usage: 0.0/1.0 CPU 0.00/0.931 GiB memory 0.00/0.200 GiB object_store_memory Demands: (no resource demands) Known issues and limitations \u00b6 The operator will recognize the following setting and automatically inject a preconfigured autoscaler container to the head pod. The service account, role, and role binding needed by the autoscaler will be created by the operator out-of-box. The operator will also configure an empty-dir logging volume for the Ray head pod. The volume will be mounted into the Ray and autoscaler containers; this is necessary to support the event logging introduced in Ray PR #13434 . spec: rayVersion: 'nightly' enableInTreeAutoscaling: true The autoscaler image is rayproject/ray:448f52 which reflects the latest changes from Ray PR #24718 in the master branch. Autoscaling functionality is supported only with Ray versions at least as new as 1.11.0. The autoscaler image used is compatible with all Ray versions >= 1.11.0. Test autoscaling \u00b6 Let's now try out the autoscaler. We can run the following command to get a Python interpreter in the head pod: kubectl exec `kubectl get pods -o custom-columns=POD:metadata.name | grep raycluster-autoscaler-head` -it -c ray-head -- python In the Python interpreter, run the following snippet to scale up the cluster: import ray.autoscaler.sdk ray.init(\"auto\") ray.autoscaler.sdk.request_resources(num_cpus=4) You can see new ray nodes (pods) are joinning the cluster if the default node group doesn't have enough resources.","title":"Autoscaling"},{"location":"guidance/autoscaler/#autoscaler-experimental","text":"Note: This feature is still experimental, there're few limitations and stabilization will be done in future release from both Ray and KubeRay side.","title":"Autoscaler (Experimental)"},{"location":"guidance/autoscaler/#prerequisite","text":"You have to use nightly operator images because autoscaler support is merged recently. You can follow below steps for a quick deployment. git clone https://github.com/ray-project/kuberay.git cd kuberay kubectl create -k manifests/cluster-scope-resources kubectl apply -k manifests/overlays/autoscaling Note: For compatibility with the Ray autoscaler, the KubeRay Operator's entrypoint must include the flag --prioritize-workers-to-delete . The kustomization overlay manifests/overlays/autoscaling provided in the last command above adds the necessary flag.","title":"Prerequisite"},{"location":"guidance/autoscaler/#deploy-a-cluster-with-autoscaling-enabled","text":"kubectl apply -f ray-operator/config/samples/ray-cluster.autoscaler.yaml To verify autoscaler is working, Do not trust READY container status because autoscaler container has in-built retry and even there's error, it won't crash now. $ kubectl get pods NAME READY STATUS RESTARTS AGE raycluster-autoscaler-head-mgwwk 2/2 Running 0 4m41s The recommended way is to check containers logs. Here's an example of well-behaved autoscaler. kubectl logs -f raycluster-autoscaler-head-mgwwk autoscaler 2022-03-10 07:51:22,616 INFO monitor.py:226 -- Starting autoscaler metrics server on port 44217 2022-03-10 07:51:22,621 INFO monitor.py:243 -- Monitor: Started 2022-03-10 07:51:22,824 INFO node_provider.py:143 -- Creating KuberayNodeProvider. 2022-03-10 07:51:22,825 INFO autoscaler.py:282 -- StandardAutoscaler: {'provider': {'type': 'kuberay', 'namespace': 'default', 'disable_node_updaters': True, 'disable_launch_config_check': True}, 'cluster_name': 'raycluster-autoscaler', 'head_node_type': 'head-group', 'available_node_types': {'head-group': {'min_workers': 0, 'max_workers': 0, 'node_config': {}, 'resources': {'CPU': 1}}, 'small-group': {'min_workers': 1, 'max_workers': 300, 'node_config': {}, 'resources': {'CPU': 1}}}, 'max_workers': 300, 'idle_timeout_minutes': 5, 'upscaling_speed': 1, 'file_mounts': {}, 'cluster_synced_files': [], 'file_mounts_sync_continuously': False, 'initialization_commands': [], 'setup_commands': [], 'head_setup_commands': [], 'worker_setup_commands': [], 'head_start_ray_commands': [], 'worker_start_ray_commands': [], 'auth': {}, 'head_node': {}, 'worker_nodes': {}} 2022-03-10 07:51:23,027 INFO autoscaler.py:327 -- ======== Autoscaler status: 2022-03-10 07:51:23.027271 ======== Node status --------------------------------------------------------------- Healthy: 1 head-group Pending: (no pending nodes) Recent failures: (no failures) Resources --------------------------------------------------------------- Usage: 0.0/1.0 CPU 0.00/0.931 GiB memory 0.00/0.200 GiB object_store_memory Demands: (no resource demands)","title":"Deploy a cluster with autoscaling enabled"},{"location":"guidance/autoscaler/#known-issues-and-limitations","text":"The operator will recognize the following setting and automatically inject a preconfigured autoscaler container to the head pod. The service account, role, and role binding needed by the autoscaler will be created by the operator out-of-box. The operator will also configure an empty-dir logging volume for the Ray head pod. The volume will be mounted into the Ray and autoscaler containers; this is necessary to support the event logging introduced in Ray PR #13434 . spec: rayVersion: 'nightly' enableInTreeAutoscaling: true The autoscaler image is rayproject/ray:448f52 which reflects the latest changes from Ray PR #24718 in the master branch. Autoscaling functionality is supported only with Ray versions at least as new as 1.11.0. The autoscaler image used is compatible with all Ray versions >= 1.11.0.","title":"Known issues and limitations"},{"location":"guidance/autoscaler/#test-autoscaling","text":"Let's now try out the autoscaler. We can run the following command to get a Python interpreter in the head pod: kubectl exec `kubectl get pods -o custom-columns=POD:metadata.name | grep raycluster-autoscaler-head` -it -c ray-head -- python In the Python interpreter, run the following snippet to scale up the cluster: import ray.autoscaler.sdk ray.init(\"auto\") ray.autoscaler.sdk.request_resources(num_cpus=4) You can see new ray nodes (pods) are joinning the cluster if the default node group doesn't have enough resources.","title":"Test autoscaling"},{"location":"guidance/ingress/","text":"Ingress Usage \u00b6 Prerequisite \u00b6 It's user's responsibility to install ingress controller by themselves. Technically, any ingress controller implementation should work well. In order to pass through the customized ingress configuration, you can annotate RayCluster object and controller will pass to ingress object. kubernetes.io/ingress.class is recommended. Note: If the ingressClassName is omitted, a default Ingress class should be defined. Please make sure default ingress class is created. apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: annotations: kubernetes.io/ingress.class: nginx -> this is required spec: rayVersion: '1.9.2' headGroupSpec: serviceType: NodePort enableIngress: true # enables ingress","title":"Ingress"},{"location":"guidance/ingress/#ingress-usage","text":"","title":"Ingress Usage"},{"location":"guidance/ingress/#prerequisite","text":"It's user's responsibility to install ingress controller by themselves. Technically, any ingress controller implementation should work well. In order to pass through the customized ingress configuration, you can annotate RayCluster object and controller will pass to ingress object. kubernetes.io/ingress.class is recommended. Note: If the ingressClassName is omitted, a default Ingress class should be defined. Please make sure default ingress class is created. apiVersion: ray.io/v1alpha1 kind: RayCluster metadata: annotations: kubernetes.io/ingress.class: nginx -> this is required spec: rayVersion: '1.9.2' headGroupSpec: serviceType: NodePort enableIngress: true # enables ingress","title":"Prerequisite"},{"location":"release/","text":"KubeRay Release Process \u00b6 Prerequisite \u00b6 Github Write permissions to cut a release tag/branch. Dockerhub Write permissions to push images with pinned tag. Release Process \u00b6 Make sure the last commit you want to release past Go-build-and-test workflow. Check out that commit (in this example, we'll use 6214e560 ). Depends on what version you want to release, Major or Minor version - Use the GitHub UI to cut a release branch and name the release branch v{MAJOR}.${MINOR}-branch Patch version - You don't need to cut release branch on patch version. Tag the image version from kuberay/operator:6214e560 to kuberay/operator:v0.2.0 and push to dockerhub. docker tag kuberay/operator:6214e560 kuberay/operator:v0.2.0 docker push kuberay/operator:v0.2.0 docker tag kuberay/apiserver:6214e560 kuberay/apiserver:v0.2.0 docker push kuberay/apiserver:v0.2.0 Build CLI with multi arch support and they will be uploaded as release artifacts in later step. Create a new PR against the release branch to change container image in manifest to point to that commit hash. images: - name: kuberay/operator newName: kuberay/operator newTag: v0.2.0 ... note: post submit job will always build a new image using the PULL_BASE_HASH as image tag. Create a tag and push tag to upstream. git tag v0.2.0 git push upstream v0.2.0 Run following code and fetch online git commits from last release (v0.1.0) to current release (v0.2.0). git log v0.1.0..v0.2.0 --oneline Generate release notes and update Github release. See v0.1.0 example here . Please also upload CLI binaries. Send a PR to update CHANGELOG.md","title":"KubeRay Release Process"},{"location":"release/#kuberay-release-process","text":"","title":"KubeRay Release Process"},{"location":"release/#prerequisite","text":"Github Write permissions to cut a release tag/branch. Dockerhub Write permissions to push images with pinned tag.","title":"Prerequisite"},{"location":"release/#release-process","text":"Make sure the last commit you want to release past Go-build-and-test workflow. Check out that commit (in this example, we'll use 6214e560 ). Depends on what version you want to release, Major or Minor version - Use the GitHub UI to cut a release branch and name the release branch v{MAJOR}.${MINOR}-branch Patch version - You don't need to cut release branch on patch version. Tag the image version from kuberay/operator:6214e560 to kuberay/operator:v0.2.0 and push to dockerhub. docker tag kuberay/operator:6214e560 kuberay/operator:v0.2.0 docker push kuberay/operator:v0.2.0 docker tag kuberay/apiserver:6214e560 kuberay/apiserver:v0.2.0 docker push kuberay/apiserver:v0.2.0 Build CLI with multi arch support and they will be uploaded as release artifacts in later step. Create a new PR against the release branch to change container image in manifest to point to that commit hash. images: - name: kuberay/operator newName: kuberay/operator newTag: v0.2.0 ... note: post submit job will always build a new image using the PULL_BASE_HASH as image tag. Create a tag and push tag to upstream. git tag v0.2.0 git push upstream v0.2.0 Run following code and fetch online git commits from last release (v0.1.0) to current release (v0.2.0). git log v0.1.0..v0.2.0 --oneline Generate release notes and update Github release. See v0.1.0 example here . Please also upload CLI binaries. Send a PR to update CHANGELOG.md","title":"Release Process"}]}